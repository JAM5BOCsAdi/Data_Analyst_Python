{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries:\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "# smtplib -> For sending emails:\n",
    "import smtplib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Title: LG UltraGear 24GN60R-B\n",
      "Price: 54 590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to website:\n",
    "# https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ\n",
    "\n",
    "# If you click on something:\n",
    "# https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ?customId=B0752XJYNL&customizationToken=MC_Assembly_1%23B0752XJYNL&th=1\n",
    "url = \"https://www.arukereso.hu/monitor-c3126/\"\n",
    "\n",
    "# Get these informations from here: https://httpbin.org/get\n",
    "my_headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"}\n",
    "\n",
    "page = requests.get(url, headers = my_headers)\n",
    "\n",
    "soup1 = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "\n",
    "# print(soup2)\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "\n",
    "# https://stackoverflow.com/questions/57462202/attributeerror-nonetype-object-has-no-attribute-get-text\n",
    "# # <div class=\"price\">\n",
    "# #              54 590 Ft-t√≥l\n",
    "# #             </div>\n",
    "title = soup2.find(class_='name ulined-link').find('a').get_text()\n",
    "# <a data-akl2pp=\"1\" data-dl-si-ref=\"div#dl-si-876166542\" href=\"https://www.arukereso.hu/monitor-c3126/lg/ultragear-24gn60r-b-p876166542/\" onclick=\"_akq.push(['ak.google.trackEvent','Category','Jump to product page','Product name']);return true;\" title=\"LG UltraGear 24GN60R-B Monitor\">\n",
    "#               LG UltraGear 24GN60R-B Monitor\n",
    "#              </a>\n",
    "price = soup2.find(class_='price').get_text()\n",
    "\n",
    "title = title.strip()[:-8]\n",
    "price = price.strip()[:-7]\n",
    "\n",
    "\n",
    "print(f\"Title: {title}\")\n",
    "print(f\"Price: {price}\")\n",
    "\n",
    "type(price)\n",
    "# ------------------------------------------- All the elements (Monitors) and Prices -----------------------------------------------------------\n",
    "# Find all elements with class \"name ulined-link\"\n",
    "# monitor_elements = soup2.find_all(class_='name ulined-link')\n",
    "\n",
    "# for monitor in monitor_elements:\n",
    "#     # Extract the name\n",
    "#     name_element = monitor.find('a')\n",
    "#     name = name_element.get_text(strip=True)[:-8] if name_element else \"Name not found\"\n",
    "\n",
    "#     # Extract the price\n",
    "#     price_element = monitor.find_next(class_='price')\n",
    "#     price = price_element.get_text(strip=True)[:-7] if price_element else \"Price not found\"\n",
    "\n",
    "#     print(\"Name:\", name)\n",
    "#     print(\"Price:\", price)\n",
    "#     print(\"-----------------------------------------------\")\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "my_header = ['Title', 'Price']\n",
    "data = [title, price]\n",
    "\n",
    "# type(data)\n",
    "\n",
    "# Create CSV:\n",
    "# Save to a file_path:\n",
    "directory = 'C:/Users/Adam/Documents/Data_Analyst_Projects/Python/Jupyter/Web_Scraping/files/'\n",
    "file_name = 'ArukeresoWebScraping'\n",
    "file_type_csv = '.csv'\n",
    "file_type_xlsx = '.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "def file_dir(directory_dir, file_name_dir, file_type_dir):\n",
    "   file_path = os.path.join(directory_dir,  f\"{file_name_dir}{file_type_dir}\")\n",
    "   return file_path\n",
    "   \n",
    "file_save_csv = file_dir(directory, file_name, file_type_csv)\n",
    "with open(file_save_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "   writer =  csv.writer(f)\n",
    "   writer.writerow(my_header)\n",
    "   writer.writerow(data)\n",
    "   \n",
    "   \n",
    "# Create EXCEL:\n",
    "import openpyxl\n",
    "\n",
    "# Create a new Workbook and add a Worksheet\n",
    "workbook = openpyxl.Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "# Write the header to the first row\n",
    "sheet.append(my_header)\n",
    "\n",
    "# Write the data to the second row\n",
    "sheet.append(data)\n",
    "\n",
    "file_save_xlsx = file_dir(directory, file_name, file_type_xlsx)\n",
    "workbook.save(file_save_xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
